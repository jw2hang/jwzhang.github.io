---
title: "Free Draft-and-Verification: Toward Lossless Parallel Decoding for Diffusion Large Language Models"
date: 2025-09-30
publishDate: 2025-09-30T09:48:22.161686Z
authors: ["Shutong Wu", "Jiawei Zhang"]
publication_types: ["2"]
abstract: "Diffusion Large Language Models (DLLMs) have emerged as a new paradigm of language modeling beyond autoregressive next-token prediction. Thanks to their bidirectional attention mechanism, DLLMs are more capable of capturing the connection of context, and thus show unique advantages in challenges like the famous "reversal curse" or learning under data-constrained scenarios. However, this bidirectional nature also brings an obstacle that DLLMs are not inherently compatible with KV Cache, and consequently, the inference efficiency is not competitive compared with autoregressive models. Taking advantage of their inherent capability of multi-token prediction, existing parallel decoding algorithms can speed up the DLLM inference, but at the cost of non-negligible performance degradation. To overcome this challenge, we introduce Free Draft-and-Verification (Freedave), a novel fast sampling algorithm tailored for DLLMs that achieves lossless parallel decoding. Specifically, we propose a pipeline of parallel-decoded candidate generation and verification, which is guaranteed to reproduce the same sequence generated by static sampling, without introducing extra model forward calls. By applying Freedave, the throughput of DLLMs can be boosted up to 2.8Ã— without performance degradation on math reasoning tasks."
featured: false
publication: "*arXiv preprint arXiv:2510.00294*"
---
